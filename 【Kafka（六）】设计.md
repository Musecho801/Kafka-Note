# 【Kafka】设计

具体参考官网 https://kafka.apache.org/documentation/#design

这里只提炼简要



## 1.动机

将 Kafka 设计为能够作为一个统一平台来 处理大型公司可能拥有的所有实时数据馈送。

必须具有高吞吐量

能够处理大量数据积压

必须处理低延迟交付

分区和消费者模型

故障时保证容错



## 2.持久性

1）文件系统

Kafka**使用文件系统**（在磁盘中）、**依赖页面缓存**，来存储数据。

2）恒定时间

消息传递系统中使用的持久队列建立在简单的读取和附加到文件的基础上。这种结构的优点是所有操作都是 O(1) 。

因为磁盘的容量大、价格较低，所以在Kafka中，我们可以将消息保留较长时间（比如一周），不需要在消息被消费后立即删除。



## 3.效率

### （一）两个低效率问题的解决

使用磁盘访问模式的系统有两个常见的低效率原因：过多的小 I/O 操作和过多的字节复制。

1）过多的小 I/O 操作

为了避免这种情况，我们的协议围绕“message set（消息集）“抽象概念构建。这允许网络请求将消息组合在一起并分摊网络往返的开销，而不是一次发送一条消息。**服务器依次将消息块一次性添加到其日志中，消费者一次获取大的线性块**。

这种简单的优化产生了数量级的加速。批处理会导致更大的网络数据包、更大的顺序磁盘操作、连续的内存块等，所有这些都允许 Kafka 将突发的随机消息的写入流转换为流向消费者的线性写入。

2）过多的字节复制

在低消息速率下这不是问题，但在负载下影响是显着的。为了避免这种情况，我们采用了一种**由producer、broker和consumer共享的标准化二进制消息格式**（因此数据块可以在它们之间传输而无需修改）。

代理维护的消息日志本身只是一个文件的目录，每个文件都由一系列消息集填充，这些消息集以生产者和消费者使用的相同格式写入磁盘。保持这种通用格式可以优化最重要的操作：持久日志块的网络传输。



### （二）端到端批量压缩

解决网络带宽的问题：

Kafka可以将一批消息压缩在一起并以这种形式发送到服务器。这批消息将以压缩形式写入，并在日志中保持压缩状态，只会被消费者解压。



## 4.生产者 Producer

### （一）负载均衡

为了使 Producer 能将数据直接发送到作为分区leader的broker，所有 Kafka 节点都可以在任何给定时间 回答有关哪些服务器处于活动状态以及topic分区的leader在哪里的元数据请求。

客户端控制**将消息发布到哪个分区**。这**可以随机完成**，实现一种随机负载平衡，或者**可以通过一些语义分区函数来完成**。我们公开了语义分区的接口。



### （二）异步发送

Kafka 的 Producer 将尝试在内存中积累数据并在单个请求中发送更大的批次。批处理可以配置为累积不超过固定数量的消息，等待时间不超过某个固定的延迟限制。这种缓冲是可配置的。



## 5.消费者 Consumer

Kafka 消费者通过向想要消费的分区的代理发出“获取”请求来工作。消费者在每个请求的日志中指定其偏移量，并从该位置开始接收一个日志块。因此，消费者对该位置具有显着的控制权，并且可以在需要时将其倒回以重新消费数据。



### （一）选择push还是pull

- 推送系统：生产者将数据推送到broker，broker推送给消费者。

  缺点：当消费率低于生产率时，消费者往往会不知所措（本质上是拒绝服务攻击 a denial of service attack ）。

- **Kafka采用拉式系统：生产者将数据推送到broker，由消费者从broker拉取。**

  优点：

  - 消费者只是落后并在可能的时候赶上。

  - 有助于对发送给消费者的数据进行积极的批处理。

    基于推送的系统必须选择立即发送请求或积累更多数据，然后在不知道下游消费者是否能够立即处理它的情况下发送。

  缺点的解决：

  - 如果broker没有数据，消费者最终可能会在一个紧密的循环中轮询，实际上是忙于等待数据到达。
  - 为了避免这种情况，我们在拉取请求中设置了参数，允许消费者请求在“长轮询”中阻塞，等待数据到达（并且可以选择等待给定数量的字节可用以确保大传输大小）。



### （二）消费者定位 Consumer Position

一个消息系统的重要性能之一是，**追踪什么消息被消耗了**。

Kafka 的主题分为一组完全有序的分区，每个分区在任何给定时间由每个订阅消费者组中的一个消费者消费。**消费者在每个分区中的位置只是一个整数，即要消费的下一条消息的偏移量。**这使得关于已消费内容的状态非常小，每个分区只有一个数字。可以定期检查此状态。这使得等效的消息确认非常便宜。

附带好处是，消费者可以故意**倒回到旧的偏移量并重新消费数据**。



### （三）离线数据加载

可扩展的持久性允许消费者仅定期消费，例如批量数据加载。



### （四）静态成员资格

Kafka 的组管理协议（Group membership）允许组成员提供持久的实体 ID。组成员身份基于这些 id 保持不变，因此不会触发重新平衡。



## 6.消息传递语义

 Kafka 在生产者和消费者之间提供的语义保证。显然，可以提供多种可能的消息传递保证：

- *最多一次——*消息可能会丢失，但永远不会重新传递。
- *至少一次——*消息永远不会丢失，但可能会重新传递。
- *恰好一次*——这是人们真正想要的，每条消息只传递一次。

这分为两个问题：发布消息的持久性保证和消费消息时的保证。



### （一）发布消息的持久性保证

#### 生产者的角度

当发布消息时，我们有一个消息被“提交”到日志的概念。一旦已发布的消息被提交，只要复制该消息所写入分区的一个代理保持“活动”，它就不会丢失。

从 0.11.0.0 开始，Kafka **生产者支持幂等传递**选项，以**保证重新发送不会导致日志中出现重复条目**。为了实现这一点，代理为每个生产者分配一个 ID 并使用生产者随每条消息发送的序列号对消息进行重复数据删除。

生产者还**支持使用类似事务的语义将消息发送到多个主题分区**的能力：**要么所有消息都成功写入，要么都没有写入。**

并非所有用例都需要如此强大的保证。对于延迟敏感的用途，我们允许生产者指定它所需的持久性级别。如果生产者指定它要等待正在提交的消息，则这可能需要 10 毫秒的时间。然而，生产者也可以指定它想要完全异步地执行发送，或者它只想等到领导者（但不一定是追随者）收到消息。



### （二）消费消息时的保证

#### 消费者的角度

所有副本都具有完全相同的日志和相同的偏移量。消费者控制其在此日志中的位置。如果消费者从未崩溃，它可以只将这个位置存储在内存中，但是如果消费者失败并且我们希望这个主题分区被另一个进程接管，新进程将需要选择一个合适的位置开始处理。



<u>从 Kafka 主题消费并生成另一个主题时</u>（如在Kafka Streams 中的应用程序），我们可以利用上面提到的 0.11.0.0 中新的**事务性生产者功能**。**消费者的位置作为消息存储在主题中，因此我们可以在与接收处理数据的输出主题相同的事务中将偏移量写入 Kafka**。如果**交易被中止，消费者的位置将恢复到其旧值，并且其他消费者将无法看到输出主题上产生的数据**，这取决于他们的“隔离级别”。在默认的“read_uncommitted”隔离级别中，所有消息对消费者都是可见的，即使它们是中止事务的一部分，但在“read_committed”中，消费者只会返回来自已提交事务的消息（以及任何不属于该事务的消息）交易）。



<u>写入外部系统时</u>，限制在于需要协调消费者的位置与实际存储输出的内容。这通过**让消费者将其偏移量存储在与其输出相同的位置**来解决。



**因此 Kafka 在 Kafka Streams 中有效地支持 ”恰好一次交付“，并且事务性生产者/消费者通常可用于在 Kafka topics之间传输和处理数据时提供一次性交付。**

**Kafka 默认保证至少一次交付**，并允许用户通过在处理一批消息之前禁用对生产者的重试和在消费者中提交偏移量来实现至少一次交付。



## 7.复制

Kafka 在可配置数量的服务器上复制每个主题分区的日志（您可以逐个主题地设置此复制因子）。这允许在集群中的服务器发生故障时自动故障转移到这些副本，以便在出现故障时消息仍然可用。

复制单位是主题分区。在非故障条件下，**Kafka 中的每个分区都有一个leader和零个或多个follower。包括leader在内的副本总数构成了复制因子。所有读取和写入都转到分区的leader。**通常，分区比代理多得多，并且leader在代理之间均匀分布。**follower上的日志与leader的日志相同——都具有相同的偏移量和相同顺序的消息**（当然，在任何给定时间，leader在其日志末尾可能有一些尚未复制的消息）。

follower像普通的 Kafka 消费者一样消费来自leader的消息，并将它们应用到自己的日志中。让follower从leader那里拉取有一个很好的特性，即允许follower自然地将他们应用到他们的日志的日志条目组合在一起。



与大多数分布式系统一样，自动处理故障需要精确定义节点“活着”意味着什么。**Kafka 节点活跃度有两个条件：**

1. 节点必须能够保持与 ZooKeeper 的会话（通过 ZooKeeper 的心跳机制）
2. 如果它是一个follower，它必须复制发生在leader上的写入，并且不会落后“太远”

我们将**满足这两个条件的节点称为“同步**”。leader跟踪“同步”节点集。如果follower死亡、卡住或落后，leader会将其从同步副本列表中删除。



我们现在可以更精确地定义，**当该分区的所有同步副本已将消息应用于其日志时，该消息被视为已提交。只有已提交的消息才会发送给消费者。**这意味着消费者不必担心可能会看到如果leader失败可能会丢失的消息。另一方面，生产者可以选择等待消息提交或不提交，这取决于他们对延迟和持久性之间权衡的偏好。此首选项由生产者使用的 acks 设置控制。请注意，主题具有同步副本的“最小数量”设置，当生产者请求确认消息已写入完整的同步副本集时，会检查该设置。

Kafka 提供的保证是提交的消息不会丢失，只要同步副本中至少有一个始终处于活动状态。

在短暂的故障转移期后，如果出现节点故障，Kafka 将保持可用，但在出现网络分区时可能无法保持可用。



### （一）复制日志：仲裁、ISR (同步副本)和状态机

Kafka 分区的核心是一个复制日志。

复制日志模拟了就一系列值的顺序达成共识的过程（通常将日志条目编号为 0、1、2、...）。有很多方法可以实现这一点，但最简单和最快的方法是让领导者选择提供给它的值的顺序。只要领导者还活着，所有的追随者只需要复制领导者选择的值和顺序。

当然，如果领导者没有失败，我们就不需要追随者！当领导者确实死亡时，我们需要从追随者中选择一个新的领导者。但是追随者本身可能会落后或崩溃，因此我们必须确保选择最新的追随者。日志复制算法必须提供的基本保证是，如果我们告诉客户端一条消息已提交，并且领导者失败，那么我们选择的新领导者也必须拥有该消息。这产生了一个权衡：如果领导者在宣布消息提交之前等待更多的追随者确认消息，那么将会有更多的潜在选举领导者。

如果您选择所需的确认数量和必须比较的日志数量以选举领导者以保证重叠，则这称为法定人数。

Kafka 选择仲裁集的方法是，**动态维护一组同步副本（ISR）**，这些副本赶上领导者。**只有这个集合的成员才有资格被选举为领导者**。**在所有同步副本都收到写入之前，不会认为对 Kafka 分区的写入已提交**。每当它发生变化时，这个 ISR 集就会被持久化到 ZooKeeper。因为这个，在ISR中的任何一个副本都能被选举为leader。这是 Kafka 使用该模型的一个重要因素，其中有许多分区并且确保领导权平衡很重要。有了这个 ISR 模型和 f+1 个副本，一个 Kafka 主题可以容忍 f 个失败而不会丢失已提交的消息。

另一个重要的设计区别是 Kafka 不要求崩溃的节点在所有数据完好无损的情况下恢复。我们允许副本重新加入 ISR 的协议，当确保在重新加入前，它必须充分再次同步即使它丢失了咋在崩溃时未刷新的数据。



### （二）不洁领导的选举：如果他们都死了怎么办？

Kafka 对数据丢失的保证是基于至少一个保持同步的副本。如果复制分区的所有节点都死了，则此保证不再成立。

当所有副本都死亡时，有两种行为可以实现：

1. 等待 ISR 中的一个副本恢复生命并选择这个副本作为领导者（希望它仍然拥有所有数据）。
2. 选择作为领导者复活的第一个副本（不一定在 ISR 中）。

这是可用性和一致性之间的简单权衡。如果我们在 ISR 中等待副本，那么只要这些副本关闭，我们就会保持不可用。如果这些副本被破坏或它们的数据丢失，那么我们将永久停机。另一方面，如果一个非同步副本恢复生机并且我们允许它成为领导者，那么它的日志就会成为事实的来源，即使它不能保证拥有每条已提交的消息。默认情况下，从 0.11.0.0 版本开始，**Kafka 选择第一个策略并倾向于等待一致的副本**。可以使用配置属性 unclean.leader.election.enable 更改此行为，以支持正常运行时间优于一致性的用例。



### （三）可用性和耐用性的保证

在写入 Kafka 时，生产者可以选择等待消息被 0，1 或所有个副本确认。**“所有副本的确认”并不能保证已分配的完整副本集已收到消息。**默认情况下，当 acks=all 时，一旦所有当前同步副本收到消息，就会发生确认。例如，如果一个主题只配置了两个副本并且一个失败（即，同步副本中只剩下一个），那么指定 acks=all 的写入将成功。但是，如果剩余的副本也失败，这些写入可能会丢失。尽管这确保了分区的最大可用性，但对于某些更喜欢持久性而不是可用性的用户来说，这种行为可能是不受欢迎的。所以，

1. **禁用不干净的领导者选举** - 如果所有副本都不可用，则分区将保持不可用，直到最近的领导者再次可用。这实际上更倾向于不可用而不是消息丢失的风险。请参阅上一节关于不洁领导人选举的说明。
2. 指定最小 ISR 大小 - 如果 ISR 的大小高于某个最小值，分区将仅接受写入，以防止丢失仅写入单个副本的消息，该副本随后变得不可用。此设置仅在生产者使用 acks=all 并保证消息将被至少这么多同步副本确认时才生效。此设置提供了一致性和可用性之间的权衡。**最小 ISR 大小的较高设置可确保更好的一致性，因为保证消息被写入更多副本，从而降低了丢失的可能性。但是，它会降低可用性，因为如果同步副本的数量低于最小阈值，则分区将不可用于写入。**



### （四）副本管理

Kafka 集群管理成百上千个分区。我们**尝试以循环方式平衡集群内的分区，以避免将高容量主题的所有分区聚集在少量节点上**。同样，我们**尝试平衡领导权，以便每个节点都是其分区的比例份额的领导者**。

优化领导选举过程也很重要，因为这是不可用的关键窗口。一个简单的领导者选举实现最终会在该节点失败时为该节点托管的所有分区运行每个分区的选举。**我们选择其中一个broker作为“控制器”。该控制器检测broker级别的故障，并负责更改故障代理中所有受影响分区的leader。结果是，我们能够将许多所需的领导层变更通知批处理在一起，这使得大量分区的选举过程更加便宜和快速。**如果控制器出现故障，幸存的代理之一将成为新的控制器。



（后面没看）

## 8.日志压缩

## 9.配额